{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8635f7",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede766af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, fbeta_score, precision_score, \\\n",
    "                            recall_score, roc_auc_score, classification_report, f1_score, roc_curve\n",
    "                            \n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8eafc7",
   "metadata": {},
   "source": [
    "### Load and split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "710c7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "#load downloaded file\n",
    "INPUT_PATH = r\"C:\\Users\\User\\Desktop\\portfolio\\cc_defaulter_prediction\\artifacts\\data_ingestion\\CreditCardClients.xls\"\n",
    "df = pd.read_excel(INPUT_PATH, header=1)\n",
    "#drop id colum\n",
    "df.drop(columns='ID', inplace=True)\n",
    "#rename columns for convenience\n",
    "df.rename(columns = {'PAY_0': 'PAY_1', 'default payment next month': 'Default'}, inplace=True)\n",
    "\n",
    "#lowering column names \n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "#split the data based on class label\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=33)\n",
    "# Use the split method to get the indices for training and testing\n",
    "strat_train_set = None\n",
    "strat_test_set = None\n",
    "for train_idx, test_idx in split.split(df, df.iloc[:,-1]):\n",
    "    df_train = df.loc[train_idx]\n",
    "    df_test = df.loc[test_idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0cf65",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bcbac",
   "metadata": {},
   "source": [
    "Train model with all the features<br>\n",
    "    - With Dummy classifier <br>\n",
    "    - With engineered features <br>\n",
    "    - Recursive Feature Engineering with Cross Validation <br>\n",
    "    - Model interpretability <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166aa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def evaluate_clf(true, predicted):\n",
    "    '''\n",
    "    Input: True values and Predicted values\n",
    "    Returns: Accuracy, F1-Score, Precision, Recall, Roc-auc Score\n",
    "    '''\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted)  # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0495f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print confusion matrix and classification report\n",
    "def display_confusion_matrix(y_true, y_pred, labels):\n",
    "    '''\n",
    "    This function takes y_ture, y_predicted, class labels and returns false positives and false negatives\n",
    "   \n",
    "    '''\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)#, normalize='all')\n",
    "    print(\"Confusion Matrix: \\n\", cm)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_true, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8596d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "\n",
    "def evaluate_models(X_train, y_train, x_test, y_test, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "   \n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "   \n",
    "    #list of measures that goes into report dataframe\n",
    "    models_list = []\n",
    "    model_train_accuracy_list = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "    model_test_accuracy_list = []\n",
    "    train_roc_auc = []\n",
    "    test_roc_auc =[]\n",
    "    train_precision =[]\n",
    "    test_precision=[]\n",
    "    train_recall=[]\n",
    "    test_recall=[]\n",
    "    f2_score = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "\n",
    "\n",
    "        # Test set performance\n",
    "        model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        model_train_accuracy_list.append(model_train_accuracy)\n",
    "        model_test_accuracy_list.append(model_test_accuracy)\n",
    "        train_f1.append(model_train_f1)\n",
    "        test_f1.append(model_test_f1)\n",
    "        train_roc_auc.append(model_train_rocauc_score)\n",
    "        test_roc_auc.append(model_test_rocauc_score)\n",
    "        train_precision.append(model_train_precision)\n",
    "        test_precision.append(model_test_precision)\n",
    "        train_recall.append(model_train_recall)\n",
    "        test_recall.append(model_test_recall)\n",
    "        f2_score.append(fbeta_score(y_test, y_test_pred, beta=2))\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        display_confusion_matrix(y_train, y_train_pred, model.classes_)\n",
    "\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        display_confusion_matrix(y_test, y_test_pred, model.classes_)\n",
    "\n",
    "        \n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "    report_data = {\n",
    "        'Model Name': models_list,\n",
    "        'Train Accuracy': model_train_accuracy_list,\n",
    "        'Test Accuracy': model_test_accuracy_list,\n",
    "        'Train_F1': train_f1,\n",
    "        'Test_F1': test_f1,\n",
    "        'Test_ROC_AUC_score': test_roc_auc,\n",
    "        'Train_ROC_AUC_score': train_roc_auc,\n",
    "        'Train_presicion': train_precision,\n",
    "        'Test_precision': test_precision,\n",
    "        'Train_recall': train_recall,\n",
    "        'Test_recall': test_recall,\n",
    "        'F2-Score': f2_score\n",
    "    }\n",
    "    \n",
    "    report = pd.DataFrame(report_data).sort_values(by=['Test_ROC_AUC_score','F2-Score', 'Test_F1'], ascending=False)        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e9458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of classification models\n",
    "models = {\n",
    "    \"Baseline Classifier\": DummyClassifier(strategy='most_frequent'),\n",
    "    \"Logistic Regression\": LogisticRegression(),#(class_weight='balanced'),\n",
    "    \"SVM\": SVC(),#(class_weight='balanced'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),#(class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(),#(class_weight='balanced'),\n",
    "    \"Gradient Boost\": GradientBoostingClassifier(),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"Extra tree\": ExtraTreesClassifier(),#(class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a673b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(numeric_features, categorical_features):#, model_name, model):\n",
    "    '''\n",
    "    input: list of numerical features and categorical features\n",
    "    applies transformers on given data\n",
    "    returns: preprocessed object\n",
    "    '''\n",
    "    \n",
    "    # Create transformers\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    #feature_generator = FeatureGenerator()\n",
    "    \n",
    "    # Create transformers\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', RobustScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "        # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532e9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'education', 'marriage','pay_1', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "numeric_cols = ['age','limit_bal', 'bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6', \\\n",
    "                 'pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6b0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('default', axis=1)\n",
    "y_train = df_train['default']\n",
    "\n",
    "x_test=df_test.drop('default', axis=1)\n",
    "y_test=df_test['default']\n",
    "num_cols = numeric_cols#+engineered_cols\n",
    "pipeline = preprocess(num_cols, categorical_features)\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "x_test_transformed = pipeline.transform(x_test)\n",
    "column_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed.toarray(), columns = column_names)\n",
    "x_test_transformed_df = pd.DataFrame(x_test_transformed.toarray(), columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba37522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [ 5309     0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     18691\n",
      "           1       0.00      0.00      0.00      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.39      0.50      0.44     24000\n",
      "weighted avg       0.61      0.78      0.68     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[4673    0]\n",
      " [1327    0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8205\n",
      "- F1 score: 0.4664\n",
      "- Precision: 0.6808\n",
      "- Recall: 0.3547\n",
      "- Roc Auc Score: 0.6537\n",
      "Confusion Matrix: \n",
      " [[17808   883]\n",
      " [ 3426  1883]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18691\n",
      "           1       0.68      0.35      0.47      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.76      0.65      0.68     24000\n",
      "weighted avg       0.80      0.82      0.80     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8237\n",
      "- F1 score: 0.4757\n",
      "- Precision: 0.6946\n",
      "- Recall: 0.3617\n",
      "- Roc Auc Score: 0.6583\n",
      "Confusion Matrix: \n",
      " [[4462  211]\n",
      " [ 847  480]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.69      0.36      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.66      0.68      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8185\n",
      "- F1 score: 0.4296\n",
      "- Precision: 0.7043\n",
      "- Recall: 0.3091\n",
      "- Roc Auc Score: 0.6361\n",
      "Confusion Matrix: \n",
      " [[18002   689]\n",
      " [ 3668  1641]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18691\n",
      "           1       0.70      0.31      0.43      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.77      0.64      0.66     24000\n",
      "weighted avg       0.80      0.82      0.79     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8200\n",
      "- F1 score: 0.4316\n",
      "- Precision: 0.7155\n",
      "- Recall: 0.3090\n",
      "- Roc Auc Score: 0.6370\n",
      "Confusion Matrix: \n",
      " [[4510  163]\n",
      " [ 917  410]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      4673\n",
      "           1       0.72      0.31      0.43      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.64      0.66      6000\n",
      "weighted avg       0.81      0.82      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8038\n",
      "- F1 score: 0.3363\n",
      "- Precision: 0.6680\n",
      "- Recall: 0.2247\n",
      "- Roc Auc Score: 0.5965\n",
      "Confusion Matrix: \n",
      " [[18098   593]\n",
      " [ 4116  1193]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     18691\n",
      "           1       0.67      0.22      0.34      5309\n",
      "\n",
      "    accuracy                           0.80     24000\n",
      "   macro avg       0.74      0.60      0.61     24000\n",
      "weighted avg       0.78      0.80      0.76     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8050\n",
      "- F1 score: 0.3449\n",
      "- Precision: 0.6710\n",
      "- Recall: 0.2321\n",
      "- Roc Auc Score: 0.5999\n",
      "Confusion Matrix: \n",
      " [[4522  151]\n",
      " [1019  308]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4673\n",
      "           1       0.67      0.23      0.34      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.60      0.62      6000\n",
      "weighted avg       0.78      0.81      0.77      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9989\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [   12  5297]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7237\n",
      "- F1 score: 0.4023\n",
      "- Precision: 0.3856\n",
      "- Recall: 0.4205\n",
      "- Roc Auc Score: 0.6151\n",
      "Confusion Matrix: \n",
      " [[3784  889]\n",
      " [ 769  558]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      4673\n",
      "           1       0.39      0.42      0.40      1327\n",
      "\n",
      "    accuracy                           0.72      6000\n",
      "   macro avg       0.61      0.62      0.61      6000\n",
      "weighted avg       0.73      0.72      0.73      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Precision: 0.9994\n",
      "- Recall: 0.9983\n",
      "- Roc Auc Score: 0.9991\n",
      "Confusion Matrix: \n",
      " [[18688     3]\n",
      " [    9  5300]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8215\n",
      "- F1 score: 0.4778\n",
      "- Precision: 0.6768\n",
      "- Recall: 0.3693\n",
      "- Roc Auc Score: 0.6596\n",
      "Confusion Matrix: \n",
      " [[4439  234]\n",
      " [ 837  490]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.68      0.37      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.66      0.69      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8260\n",
      "- F1 score: 0.4841\n",
      "- Precision: 0.7037\n",
      "- Recall: 0.3690\n",
      "- Roc Auc Score: 0.6624\n",
      "Confusion Matrix: \n",
      " [[17866   825]\n",
      " [ 3350  1959]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18691\n",
      "           1       0.70      0.37      0.48      5309\n",
      "\n",
      "    accuracy                           0.83     24000\n",
      "   macro avg       0.77      0.66      0.69     24000\n",
      "weighted avg       0.81      0.83      0.80     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8242\n",
      "- F1 score: 0.4775\n",
      "- Precision: 0.6965\n",
      "- Recall: 0.3632\n",
      "- Roc Auc Score: 0.6591\n",
      "Confusion Matrix: \n",
      " [[4463  210]\n",
      " [ 845  482]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89      4673\n",
      "           1       0.70      0.36      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.66      0.69      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8179\n",
      "- F1 score: 0.4460\n",
      "- Precision: 0.6820\n",
      "- Recall: 0.3313\n",
      "- Roc Auc Score: 0.6437\n",
      "Confusion Matrix: \n",
      " [[17871   820]\n",
      " [ 3550  1759]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18691\n",
      "           1       0.68      0.33      0.45      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.76      0.64      0.67     24000\n",
      "weighted avg       0.80      0.82      0.79     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8202\n",
      "- F1 score: 0.4537\n",
      "- Precision: 0.6914\n",
      "- Recall: 0.3376\n",
      "- Roc Auc Score: 0.6474\n",
      "Confusion Matrix: \n",
      " [[4473  200]\n",
      " [ 879  448]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89      4673\n",
      "           1       0.69      0.34      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.65      0.67      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9989\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [   12  5297]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8115\n",
      "- F1 score: 0.4795\n",
      "- Precision: 0.6158\n",
      "- Recall: 0.3926\n",
      "- Roc Auc Score: 0.6615\n",
      "Confusion Matrix: \n",
      " [[4348  325]\n",
      " [ 806  521]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4673\n",
      "           1       0.62      0.39      0.48      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.66      0.68      6000\n",
      "weighted avg       0.79      0.81      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8859\n",
      "- F1 score: 0.6830\n",
      "- Precision: 0.8862\n",
      "- Recall: 0.5557\n",
      "- Roc Auc Score: 0.7677\n",
      "Confusion Matrix: \n",
      " [[18312   379]\n",
      " [ 2359  2950]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     18691\n",
      "           1       0.89      0.56      0.68      5309\n",
      "\n",
      "    accuracy                           0.89     24000\n",
      "   macro avg       0.89      0.77      0.81     24000\n",
      "weighted avg       0.89      0.89      0.88     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8190\n",
      "- F1 score: 0.4779\n",
      "- Precision: 0.6600\n",
      "- Recall: 0.3745\n",
      "- Roc Auc Score: 0.6599\n",
      "Confusion Matrix: \n",
      " [[4417  256]\n",
      " [ 830  497]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.66      0.37      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.75      0.66      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC_score</th>\n",
       "      <th>Train_ROC_AUC_score</th>\n",
       "      <th>Train_presicion</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra tree</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.479521</td>\n",
       "      <td>0.661533</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615839</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>0.392615</td>\n",
       "      <td>0.423302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.885917</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.683028</td>\n",
       "      <td>0.477885</td>\n",
       "      <td>0.659873</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.886152</td>\n",
       "      <td>0.660027</td>\n",
       "      <td>0.555660</td>\n",
       "      <td>0.374529</td>\n",
       "      <td>0.409998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.477816</td>\n",
       "      <td>0.659590</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.676796</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.369254</td>\n",
       "      <td>0.406167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.826042</td>\n",
       "      <td>0.824167</td>\n",
       "      <td>0.484122</td>\n",
       "      <td>0.477464</td>\n",
       "      <td>0.659143</td>\n",
       "      <td>0.662429</td>\n",
       "      <td>0.703664</td>\n",
       "      <td>0.696532</td>\n",
       "      <td>0.368996</td>\n",
       "      <td>0.363225</td>\n",
       "      <td>0.401667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820458</td>\n",
       "      <td>0.823667</td>\n",
       "      <td>0.466378</td>\n",
       "      <td>0.475719</td>\n",
       "      <td>0.658283</td>\n",
       "      <td>0.653719</td>\n",
       "      <td>0.680766</td>\n",
       "      <td>0.694645</td>\n",
       "      <td>0.354681</td>\n",
       "      <td>0.361718</td>\n",
       "      <td>0.400067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.817917</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.445994</td>\n",
       "      <td>0.453671</td>\n",
       "      <td>0.647402</td>\n",
       "      <td>0.643726</td>\n",
       "      <td>0.682047</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.331324</td>\n",
       "      <td>0.337604</td>\n",
       "      <td>0.376091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818458</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.429637</td>\n",
       "      <td>0.431579</td>\n",
       "      <td>0.637043</td>\n",
       "      <td>0.636118</td>\n",
       "      <td>0.704292</td>\n",
       "      <td>0.715532</td>\n",
       "      <td>0.309098</td>\n",
       "      <td>0.308968</td>\n",
       "      <td>0.348580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.723667</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.402307</td>\n",
       "      <td>0.615128</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.385625</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>0.420497</td>\n",
       "      <td>0.413027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.803792</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.336293</td>\n",
       "      <td>0.344905</td>\n",
       "      <td>0.599895</td>\n",
       "      <td>0.596493</td>\n",
       "      <td>0.667973</td>\n",
       "      <td>0.671024</td>\n",
       "      <td>0.224713</td>\n",
       "      <td>0.232102</td>\n",
       "      <td>0.267037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Classifier</td>\n",
       "      <td>0.778792</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "8           Extra tree        0.999500       0.811500  0.998869  0.479521   \n",
       "9              XGBoost        0.885917       0.819000  0.683028  0.477885   \n",
       "5        Random Forest        0.999500       0.821500  0.998869  0.477816   \n",
       "6       Gradient Boost        0.826042       0.824167  0.484122  0.477464   \n",
       "1  Logistic Regression        0.820458       0.823667  0.466378  0.475719   \n",
       "7             Adaboost        0.817917       0.820167  0.445994  0.453671   \n",
       "2                  SVM        0.818458       0.820000  0.429637  0.431579   \n",
       "4        Decision Tree        0.999500       0.723667  0.998869  0.402307   \n",
       "3          Naive Bayes        0.803792       0.805000  0.336293  0.344905   \n",
       "0  Baseline Classifier        0.778792       0.778833  0.000000  0.000000   \n",
       "\n",
       "   Test_ROC_AUC_score  Train_ROC_AUC_score  Train_presicion  Test_precision  \\\n",
       "8            0.661533             0.998870         1.000000        0.615839   \n",
       "9            0.659873             0.767692         0.886152        0.660027   \n",
       "5            0.659590             0.999072         0.999434        0.676796   \n",
       "6            0.659143             0.662429         0.703664        0.696532   \n",
       "1            0.658283             0.653719         0.680766        0.694645   \n",
       "7            0.647402             0.643726         0.682047        0.691358   \n",
       "2            0.637043             0.636118         0.704292        0.715532   \n",
       "4            0.615128             0.998870         1.000000        0.385625   \n",
       "3            0.599895             0.596493         0.667973        0.671024   \n",
       "0            0.500000             0.500000         0.000000        0.000000   \n",
       "\n",
       "   Train_recall  Test_recall  F2-Score  \n",
       "8      0.997740     0.392615  0.423302  \n",
       "9      0.555660     0.374529  0.409998  \n",
       "5      0.998305     0.369254  0.406167  \n",
       "6      0.368996     0.363225  0.401667  \n",
       "1      0.354681     0.361718  0.400067  \n",
       "7      0.331324     0.337604  0.376091  \n",
       "2      0.309098     0.308968  0.348580  \n",
       "4      0.997740     0.420497  0.413027  \n",
       "3      0.224713     0.232102  0.267037  \n",
       "0      0.000000     0.000000  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report1 = evaluate_models(X_train=X_train_transformed_df, y_train=y_train, x_test=x_test_transformed_df, y_test=y_test, models=models)\n",
    "report1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4c45c",
   "metadata": {},
   "source": [
    "#### Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa8011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(TransformerMixin):\n",
    "    \n",
    "    '''\n",
    "    Upon calling fit_transform or transform method this column generates new dataframe columns\n",
    "    '''\n",
    "    def __init__(self):\n",
    "      \n",
    "        try:\n",
    "            self.bill_amt1_ix = \"bill_amt1\"\n",
    "            self.bill_amt2_ix = \"bill_amt2\"\n",
    "            self.bill_amt3_ix = \"bill_amt3\"\n",
    "            self.bill_amt4_ix = \"bill_amt4\"\n",
    "            self.bill_amt5_ix = \"bill_amt5\"\n",
    "            self.bill_amt6_ix = \"bill_amt6\"\n",
    "            self.limit_bal_ix = \"limit_bal\"\n",
    "            self.pay_amt1_ix = \"pay_amt1\"\n",
    "            self.pay_amt2_ix = \"pay_amt2\"\n",
    "            self.pay_amt3_ix = \"pay_amt3\"\n",
    "            self.pay_amt4_ix = \"pay_amt4\"\n",
    "            self.pay_amt5_ix = \"pay_amt5\"\n",
    "            self.pay_amt6_ix = \"pay_amt6\"\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "            X['leverage_1'] = X[self.bill_amt1_ix]/X[self.limit_bal_ix]   \n",
    "            X['leverage_2'] = X[self.bill_amt2_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_3'] = X[self.bill_amt3_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_4'] = X[self.bill_amt4_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_5'] = X[self.bill_amt5_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_6'] = X[self.bill_amt6_ix]/X[self.limit_bal_ix]\n",
    "\n",
    "            X['bill_to_pay1'] = X[self.bill_amt1_ix]/(X[self.pay_amt1_ix]+1)   \n",
    "            X['bill_to_pay2'] = X[self.bill_amt2_ix]/(X[self.pay_amt2_ix]+1)\n",
    "            X['bill_to_pay3'] = X[self.bill_amt3_ix]/(X[self.pay_amt3_ix]+1)\n",
    "            X['bill_to_pay4'] = X[self.bill_amt4_ix]/(X[self.pay_amt4_ix]+1)\n",
    "            X['bill_to_pay5'] = X[self.bill_amt5_ix]/(X[self.pay_amt5_ix]+1)\n",
    "            X['bill_to_pay6'] = X[self.bill_amt6_ix]/(X[self.pay_amt6_ix]+1)\n",
    "            \n",
    "            X['overdraft'] = np.where(   (X[self.bill_amt1_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt2_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt3_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt4_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt5_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt6_ix]>X[self.limit_bal_ix]),\n",
    "                                        1, 0                                 \n",
    "                                    )\n",
    "        '''\n",
    "        X['avg_bill_amt'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                     +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/6\n",
    "        X['avg_leverage_ratio'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                       +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/(6*X[self.limit_bal_ix])\n",
    "        X['avg_pay_amt'] = (X[self.pay_amt1_ix]+X[self.pay_amt2_ix]+X[self.pay_amt3_ix] \\\n",
    "                                      +X[self.pay_amt4_ix]+X[self.pay_amt5_ix]+X[self.pay_amt6_ix])/6\n",
    "        X['avg_bill_to_pay'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                       +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/ \\\n",
    "                                        ((X[self.pay_amt1_ix]+X[self.pay_amt2_ix]+X[self.pay_amt3_ix] \\\n",
    "                                       +X[self.pay_amt4_ix]+X[self.pay_amt5_ix]+X[self.pay_amt6_ix])+1)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e8791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess1(numeric_features, categorical_features):#, model_name, model):\n",
    "    '''\n",
    "    input: list of numerical features and categorical features\n",
    "    applies transformers on given data\n",
    "    returns: preprocessed object\n",
    "    '''\n",
    "    \n",
    "    # Create transformers\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    feature_generator = FeatureGenerator()\n",
    "    \n",
    "    # Create transformers\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', RobustScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "        # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=[('feature generator', feature_generator),('preprocessor', preprocessor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b069cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'education', 'marriage','pay_1', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "numeric_cols = ['age','limit_bal', 'bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6', \\\n",
    "                 'pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6']\n",
    "engineered_cols = ['avg_bill_amt', 'avg_leverage_ratio', 'avg_pay_amt', 'avg_bill_to_pay']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02cfe914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('default', axis=1)\n",
    "y_train = df_train['default']\n",
    "\n",
    "x_test=df_test.drop('default', axis=1)\n",
    "y_test=df_test['default']\n",
    "num_cols = numeric_cols+engineered_cols\n",
    "pipeline = preprocess1(num_cols, categorical_features)\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "x_test_transformed = pipeline.transform(x_test)\n",
    "column_names = pipeline[1:].named_steps['preprocessor'].get_feature_names_out()\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed.toarray(), columns = column_names)\n",
    "x_test_transformed_df = pd.DataFrame(x_test_transformed.toarray(), columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9730ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(pipeline[:-1].named_steps['preprocessor']).get_feature_names_out(numeric_cols)\n",
    "#pipeline.named_steps['preprocessor'].named_transformers_\n",
    "len(pipeline[1:].named_steps['preprocessor'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bfecc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [ 5309     0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     18691\n",
      "           1       0.00      0.00      0.00      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.39      0.50      0.44     24000\n",
      "weighted avg       0.61      0.78      0.68     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[4673    0]\n",
      " [1327    0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8087\n",
      "- F1 score: 0.4052\n",
      "- Precision: 0.6487\n",
      "- Recall: 0.2946\n",
      "- Roc Auc Score: 0.6246\n",
      "Confusion Matrix: \n",
      " [[17844   847]\n",
      " [ 3745  1564]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     18691\n",
      "           1       0.65      0.29      0.41      5309\n",
      "\n",
      "    accuracy                           0.81     24000\n",
      "   macro avg       0.74      0.62      0.65     24000\n",
      "weighted avg       0.79      0.81      0.78     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8128\n",
      "- F1 score: 0.4202\n",
      "- Precision: 0.6672\n",
      "- Recall: 0.3067\n",
      "- Roc Auc Score: 0.6316\n",
      "Confusion Matrix: \n",
      " [[4470  203]\n",
      " [ 920  407]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.67      0.31      0.42      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.63      0.65      6000\n",
      "weighted avg       0.79      0.81      0.78      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7801\n",
      "- F1 score: 0.0287\n",
      "- Precision: 0.6290\n",
      "- Recall: 0.0147\n",
      "- Roc Auc Score: 0.5061\n",
      "Confusion Matrix: \n",
      " [[18645    46]\n",
      " [ 5231    78]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     18691\n",
      "           1       0.63      0.01      0.03      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.70      0.51      0.45     24000\n",
      "weighted avg       0.75      0.78      0.69     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7787\n",
      "- F1 score: 0.0178\n",
      "- Precision: 0.4800\n",
      "- Recall: 0.0090\n",
      "- Roc Auc Score: 0.5031\n",
      "Confusion Matrix: \n",
      " [[4660   13]\n",
      " [1315   12]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.48      0.01      0.02      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.63      0.50      0.45      6000\n",
      "weighted avg       0.71      0.78      0.69      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8079\n",
      "- F1 score: 0.4308\n",
      "- Precision: 0.6250\n",
      "- Recall: 0.3287\n",
      "- Roc Auc Score: 0.6363\n",
      "Confusion Matrix: \n",
      " [[17644  1047]\n",
      " [ 3564  1745]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     18691\n",
      "           1       0.62      0.33      0.43      5309\n",
      "\n",
      "    accuracy                           0.81     24000\n",
      "   macro avg       0.73      0.64      0.66     24000\n",
      "weighted avg       0.79      0.81      0.78     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8123\n",
      "- F1 score: 0.4448\n",
      "- Precision: 0.6434\n",
      "- Recall: 0.3399\n",
      "- Roc Auc Score: 0.6432\n",
      "Confusion Matrix: \n",
      " [[4423  250]\n",
      " [ 876  451]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      4673\n",
      "           1       0.64      0.34      0.44      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.64      0.67      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9989\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [   12  5297]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7295\n",
      "- F1 score: 0.4066\n",
      "- Precision: 0.3949\n",
      "- Recall: 0.4190\n",
      "- Roc Auc Score: 0.6183\n",
      "Confusion Matrix: \n",
      " [[3821  852]\n",
      " [ 771  556]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      4673\n",
      "           1       0.39      0.42      0.41      1327\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.61      0.62      0.62      6000\n",
      "weighted avg       0.74      0.73      0.73      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9988\n",
      "- Precision: 0.9991\n",
      "- Recall: 0.9985\n",
      "- Roc Auc Score: 0.9991\n",
      "Confusion Matrix: \n",
      " [[18686     5]\n",
      " [    8  5301]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8240\n",
      "- F1 score: 0.4874\n",
      "- Precision: 0.6849\n",
      "- Recall: 0.3783\n",
      "- Roc Auc Score: 0.6644\n",
      "Confusion Matrix: \n",
      " [[4442  231]\n",
      " [ 825  502]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.68      0.38      0.49      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.66      0.69      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8261\n",
      "- F1 score: 0.4860\n",
      "- Precision: 0.7021\n",
      "- Recall: 0.3716\n",
      "- Roc Auc Score: 0.6634\n",
      "Confusion Matrix: \n",
      " [[17854   837]\n",
      " [ 3336  1973]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     18691\n",
      "           1       0.70      0.37      0.49      5309\n",
      "\n",
      "    accuracy                           0.83     24000\n",
      "   macro avg       0.77      0.66      0.69     24000\n",
      "weighted avg       0.81      0.83      0.80     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8217\n",
      "- F1 score: 0.4739\n",
      "- Precision: 0.6818\n",
      "- Recall: 0.3632\n",
      "- Roc Auc Score: 0.6575\n",
      "Confusion Matrix: \n",
      " [[4448  225]\n",
      " [ 845  482]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.68      0.36      0.47      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.66      0.68      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8176\n",
      "- F1 score: 0.4407\n",
      "- Precision: 0.6848\n",
      "- Recall: 0.3249\n",
      "- Roc Auc Score: 0.6412\n",
      "Confusion Matrix: \n",
      " [[17897   794]\n",
      " [ 3584  1725]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18691\n",
      "           1       0.68      0.32      0.44      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.76      0.64      0.67     24000\n",
      "weighted avg       0.80      0.82      0.79     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8208\n",
      "- F1 score: 0.4484\n",
      "- Precision: 0.7026\n",
      "- Recall: 0.3293\n",
      "- Roc Auc Score: 0.6449\n",
      "Confusion Matrix: \n",
      " [[4488  185]\n",
      " [ 890  437]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.70      0.33      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.64      0.67      6000\n",
      "weighted avg       0.81      0.82      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9977\n",
      "- Roc Auc Score: 0.9989\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [   12  5297]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8142\n",
      "- F1 score: 0.4782\n",
      "- Precision: 0.6309\n",
      "- Recall: 0.3851\n",
      "- Roc Auc Score: 0.6605\n",
      "Confusion Matrix: \n",
      " [[4374  299]\n",
      " [ 816  511]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4673\n",
      "           1       0.63      0.39      0.48      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.66      0.68      6000\n",
      "weighted avg       0.80      0.81      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8896\n",
      "- F1 score: 0.6937\n",
      "- Precision: 0.8977\n",
      "- Recall: 0.5653\n",
      "- Roc Auc Score: 0.7735\n",
      "Confusion Matrix: \n",
      " [[18349   342]\n",
      " [ 2308  3001]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     18691\n",
      "           1       0.90      0.57      0.69      5309\n",
      "\n",
      "    accuracy                           0.89     24000\n",
      "   macro avg       0.89      0.77      0.81     24000\n",
      "weighted avg       0.89      0.89      0.88     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8200\n",
      "- F1 score: 0.4906\n",
      "- Precision: 0.6557\n",
      "- Recall: 0.3919\n",
      "- Roc Auc Score: 0.6667\n",
      "Confusion Matrix: \n",
      " [[4400  273]\n",
      " [ 807  520]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      4673\n",
      "           1       0.66      0.39      0.49      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.75      0.67      0.69      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC_score</th>\n",
       "      <th>Train_ROC_AUC_score</th>\n",
       "      <th>Train_presicion</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.889583</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.693712</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.666720</td>\n",
       "      <td>0.773484</td>\n",
       "      <td>0.897697</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.565267</td>\n",
       "      <td>0.391861</td>\n",
       "      <td>0.426160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999458</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.487379</td>\n",
       "      <td>0.664432</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>0.999058</td>\n",
       "      <td>0.684857</td>\n",
       "      <td>0.998493</td>\n",
       "      <td>0.378297</td>\n",
       "      <td>0.415494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra tree</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.478241</td>\n",
       "      <td>0.660547</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630864</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>0.385079</td>\n",
       "      <td>0.417620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.826125</td>\n",
       "      <td>0.821667</td>\n",
       "      <td>0.486020</td>\n",
       "      <td>0.473943</td>\n",
       "      <td>0.657538</td>\n",
       "      <td>0.663426</td>\n",
       "      <td>0.702135</td>\n",
       "      <td>0.681754</td>\n",
       "      <td>0.371633</td>\n",
       "      <td>0.363225</td>\n",
       "      <td>0.400665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.817583</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.440726</td>\n",
       "      <td>0.448435</td>\n",
       "      <td>0.644863</td>\n",
       "      <td>0.641220</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.702572</td>\n",
       "      <td>0.324920</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>0.368465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.807875</td>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.430811</td>\n",
       "      <td>0.444773</td>\n",
       "      <td>0.643183</td>\n",
       "      <td>0.636335</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.643367</td>\n",
       "      <td>0.328687</td>\n",
       "      <td>0.339864</td>\n",
       "      <td>0.375270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.812833</td>\n",
       "      <td>0.405181</td>\n",
       "      <td>0.420237</td>\n",
       "      <td>0.631633</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>0.648693</td>\n",
       "      <td>0.667213</td>\n",
       "      <td>0.294594</td>\n",
       "      <td>0.306707</td>\n",
       "      <td>0.343866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.406581</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.394886</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>0.418990</td>\n",
       "      <td>0.413937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.503131</td>\n",
       "      <td>0.506115</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.011251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Classifier</td>\n",
       "      <td>0.778792</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "9              XGBoost        0.889583       0.820000  0.693712  0.490566   \n",
       "5        Random Forest        0.999458       0.824000  0.998775  0.487379   \n",
       "8           Extra tree        0.999500       0.814167  0.998869  0.478241   \n",
       "6       Gradient Boost        0.826125       0.821667  0.486020  0.473943   \n",
       "7             Adaboost        0.817583       0.820833  0.440726  0.448435   \n",
       "3          Naive Bayes        0.807875       0.812333  0.430811  0.444773   \n",
       "1  Logistic Regression        0.808667       0.812833  0.405181  0.420237   \n",
       "4        Decision Tree        0.999500       0.729500  0.998869  0.406581   \n",
       "2                  SVM        0.780125       0.778667  0.028713  0.017751   \n",
       "0  Baseline Classifier        0.778792       0.778833  0.000000  0.000000   \n",
       "\n",
       "   Test_ROC_AUC_score  Train_ROC_AUC_score  Train_presicion  Test_precision  \\\n",
       "9            0.666720             0.773484         0.897697        0.655738   \n",
       "5            0.664432             0.999113         0.999058        0.684857   \n",
       "8            0.660547             0.998870         1.000000        0.630864   \n",
       "6            0.657538             0.663426         0.702135        0.681754   \n",
       "7            0.644863             0.641220         0.684796        0.702572   \n",
       "3            0.643183             0.636335         0.625000        0.643367   \n",
       "1            0.631633             0.624639         0.648693        0.667213   \n",
       "4            0.618333             0.998870         1.000000        0.394886   \n",
       "2            0.503131             0.506115         0.629032        0.480000   \n",
       "0            0.500000             0.500000         0.000000        0.000000   \n",
       "\n",
       "   Train_recall  Test_recall  F2-Score  \n",
       "9      0.565267     0.391861  0.426160  \n",
       "5      0.998493     0.378297  0.415494  \n",
       "8      0.997740     0.385079  0.417620  \n",
       "6      0.371633     0.363225  0.400665  \n",
       "7      0.324920     0.329314  0.368465  \n",
       "3      0.328687     0.339864  0.375270  \n",
       "1      0.294594     0.306707  0.343866  \n",
       "4      0.997740     0.418990  0.413937  \n",
       "2      0.014692     0.009043  0.011251  \n",
       "0      0.000000     0.000000  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report2 = evaluate_models(X_train=X_train_transformed_df, y_train=y_train, x_test=x_test_transformed_df, y_test=y_test, models=models)\n",
    "report2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59a4fb",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination with Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fd3a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 84\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv_lr = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=2,\n",
    ")\n",
    "rfecv_lr.fit(X_train_transformed_df, y_train)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv_lr.n_features_}\")\n",
    "\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "# ---------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_scores = len(rfecv_lr.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.errorbar(\n",
    "    range(min_features_to_select, n_scores + min_features_to_select),\n",
    "    rfecv_lr.cv_results_[\"mean_test_score\"],\n",
    "    yerr=rfecv_lr.cv_results_[\"std_test_score\"],\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cefea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.072074</th>\n",
       "      <td>num__age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.432363</th>\n",
       "      <td>num__limit_bal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.436869</th>\n",
       "      <td>num__bill_amt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.438290</th>\n",
       "      <td>num__bill_amt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.444686</th>\n",
       "      <td>num__bill_amt5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.446471</th>\n",
       "      <td>num__bill_amt6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.448125</th>\n",
       "      <td>num__pay_amt1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.482366</th>\n",
       "      <td>num__pay_amt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.495051</th>\n",
       "      <td>num__avg_bill_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.495210</th>\n",
       "      <td>num__avg_leverage_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.495420</th>\n",
       "      <td>num__avg_pay_amt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.495367</th>\n",
       "      <td>cat__sex_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.498088</th>\n",
       "      <td>cat__sex_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.507600</th>\n",
       "      <td>cat__education_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.512759</th>\n",
       "      <td>cat__education_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.512755</th>\n",
       "      <td>cat__education_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.512746</th>\n",
       "      <td>cat__education_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.512704</th>\n",
       "      <td>cat__education_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.518474</th>\n",
       "      <td>cat__education_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.518691</th>\n",
       "      <td>cat__education_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520141</th>\n",
       "      <td>cat__marriage_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520865</th>\n",
       "      <td>cat__marriage_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520657</th>\n",
       "      <td>cat__marriage_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520492</th>\n",
       "      <td>cat__marriage_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520796</th>\n",
       "      <td>cat__pay_1_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520843</th>\n",
       "      <td>cat__pay_1_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.521043</th>\n",
       "      <td>cat__pay_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.521534</th>\n",
       "      <td>cat__pay_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.522706</th>\n",
       "      <td>cat__pay_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.523617</th>\n",
       "      <td>cat__pay_1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.523642</th>\n",
       "      <td>cat__pay_1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.521537</th>\n",
       "      <td>cat__pay_1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.523240</th>\n",
       "      <td>cat__pay_1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.521358</th>\n",
       "      <td>cat__pay_1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.523583</th>\n",
       "      <td>cat__pay_2_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.524594</th>\n",
       "      <td>cat__pay_2_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.524990</th>\n",
       "      <td>cat__pay_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.524205</th>\n",
       "      <td>cat__pay_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.525064</th>\n",
       "      <td>cat__pay_2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.523457</th>\n",
       "      <td>cat__pay_2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.525625</th>\n",
       "      <td>cat__pay_2_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.524663</th>\n",
       "      <td>cat__pay_2_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.526439</th>\n",
       "      <td>cat__pay_2_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.526802</th>\n",
       "      <td>cat__pay_2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.528860</th>\n",
       "      <td>cat__pay_2_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.528619</th>\n",
       "      <td>cat__pay_3_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.530337</th>\n",
       "      <td>cat__pay_3_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529879</th>\n",
       "      <td>cat__pay_3_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529800</th>\n",
       "      <td>cat__pay_3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529191</th>\n",
       "      <td>cat__pay_3_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.528759</th>\n",
       "      <td>cat__pay_3_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529919</th>\n",
       "      <td>cat__pay_3_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.530353</th>\n",
       "      <td>cat__pay_3_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529334</th>\n",
       "      <td>cat__pay_3_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.530017</th>\n",
       "      <td>cat__pay_3_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.530271</th>\n",
       "      <td>cat__pay_3_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.529227</th>\n",
       "      <td>cat__pay_4_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531462</th>\n",
       "      <td>cat__pay_4_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531638</th>\n",
       "      <td>cat__pay_4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531430</th>\n",
       "      <td>cat__pay_4_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532501</th>\n",
       "      <td>cat__pay_4_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532708</th>\n",
       "      <td>cat__pay_4_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532479</th>\n",
       "      <td>cat__pay_4_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532595</th>\n",
       "      <td>cat__pay_4_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532091</th>\n",
       "      <td>cat__pay_4_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532340</th>\n",
       "      <td>cat__pay_4_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531555</th>\n",
       "      <td>cat__pay_5_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531324</th>\n",
       "      <td>cat__pay_5_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531582</th>\n",
       "      <td>cat__pay_5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531331</th>\n",
       "      <td>cat__pay_5_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531608</th>\n",
       "      <td>cat__pay_5_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532167</th>\n",
       "      <td>cat__pay_5_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532152</th>\n",
       "      <td>cat__pay_5_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532540</th>\n",
       "      <td>cat__pay_5_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532430</th>\n",
       "      <td>cat__pay_5_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532830</th>\n",
       "      <td>cat__pay_6_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532992</th>\n",
       "      <td>cat__pay_6_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.533192</th>\n",
       "      <td>cat__pay_6_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.533030</th>\n",
       "      <td>cat__pay_6_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.533148</th>\n",
       "      <td>cat__pay_6_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532922</th>\n",
       "      <td>cat__pay_6_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.533327</th>\n",
       "      <td>cat__pay_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.532870</th>\n",
       "      <td>cat__pay_6_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.533790</th>\n",
       "      <td>cat__pay_6_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "0.072074                 num__age\n",
       "0.432363           num__limit_bal\n",
       "0.436869           num__bill_amt3\n",
       "0.438290           num__bill_amt4\n",
       "0.444686           num__bill_amt5\n",
       "0.446471           num__bill_amt6\n",
       "0.448125            num__pay_amt1\n",
       "0.482366            num__pay_amt2\n",
       "0.495051        num__avg_bill_amt\n",
       "0.495210  num__avg_leverage_ratio\n",
       "0.495420         num__avg_pay_amt\n",
       "0.495367               cat__sex_1\n",
       "0.498088               cat__sex_2\n",
       "0.507600         cat__education_0\n",
       "0.512759         cat__education_1\n",
       "0.512755         cat__education_2\n",
       "0.512746         cat__education_3\n",
       "0.512704         cat__education_4\n",
       "0.518474         cat__education_5\n",
       "0.518691         cat__education_6\n",
       "0.520141          cat__marriage_0\n",
       "0.520865          cat__marriage_1\n",
       "0.520657          cat__marriage_2\n",
       "0.520492          cat__marriage_3\n",
       "0.520796            cat__pay_1_-2\n",
       "0.520843            cat__pay_1_-1\n",
       "0.521043             cat__pay_1_0\n",
       "0.521534             cat__pay_1_1\n",
       "0.522706             cat__pay_1_2\n",
       "0.523617             cat__pay_1_3\n",
       "0.523642             cat__pay_1_4\n",
       "0.521537             cat__pay_1_5\n",
       "0.523240             cat__pay_1_6\n",
       "0.521358             cat__pay_1_7\n",
       "0.523583            cat__pay_2_-2\n",
       "0.524594            cat__pay_2_-1\n",
       "0.524990             cat__pay_2_0\n",
       "0.524205             cat__pay_2_1\n",
       "0.525064             cat__pay_2_2\n",
       "0.523457             cat__pay_2_3\n",
       "0.525625             cat__pay_2_4\n",
       "0.524663             cat__pay_2_5\n",
       "0.526439             cat__pay_2_6\n",
       "0.526802             cat__pay_2_7\n",
       "0.528860             cat__pay_2_8\n",
       "0.528619            cat__pay_3_-2\n",
       "0.530337            cat__pay_3_-1\n",
       "0.529879             cat__pay_3_0\n",
       "0.529800             cat__pay_3_1\n",
       "0.529191             cat__pay_3_2\n",
       "0.528759             cat__pay_3_3\n",
       "0.529919             cat__pay_3_4\n",
       "0.530353             cat__pay_3_5\n",
       "0.529334             cat__pay_3_6\n",
       "0.530017             cat__pay_3_7\n",
       "0.530271             cat__pay_3_8\n",
       "0.529227            cat__pay_4_-1\n",
       "0.531462             cat__pay_4_0\n",
       "0.531638             cat__pay_4_1\n",
       "0.531430             cat__pay_4_2\n",
       "0.532501             cat__pay_4_3\n",
       "0.532708             cat__pay_4_4\n",
       "0.532479             cat__pay_4_5\n",
       "0.532595             cat__pay_4_6\n",
       "0.532091             cat__pay_4_7\n",
       "0.532340             cat__pay_4_8\n",
       "0.531555            cat__pay_5_-1\n",
       "0.531324             cat__pay_5_0\n",
       "0.531582             cat__pay_5_2\n",
       "0.531331             cat__pay_5_3\n",
       "0.531608             cat__pay_5_4\n",
       "0.532167             cat__pay_5_5\n",
       "0.532152             cat__pay_5_6\n",
       "0.532540             cat__pay_5_7\n",
       "0.532430             cat__pay_5_8\n",
       "0.532830            cat__pay_6_-2\n",
       "0.532992            cat__pay_6_-1\n",
       "0.533192             cat__pay_6_0\n",
       "0.533030             cat__pay_6_3\n",
       "0.533148             cat__pay_6_4\n",
       "0.532922             cat__pay_6_5\n",
       "0.533327             cat__pay_6_6\n",
       "0.532870             cat__pay_6_7\n",
       "0.533790             cat__pay_6_8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.DataFrame(rfecv_lr.get_feature_names_out(),rfecv_lr.cv_results_[\"mean_test_score\"][:84])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9753cf1",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69ac269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'features': rfecv_lr.get_feature_names_out(), 'importance': rfecv_lr.estimator_.coef_[0]}) \\\n",
    "                            .sort_values(by = 'importance', ascending=False)\n",
    "feature_importance = feature_importance[feature_importance['importance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed6ab1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [ 5309     0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     18691\n",
      "           1       0.00      0.00      0.00      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.39      0.50      0.44     24000\n",
      "weighted avg       0.61      0.78      0.68     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[4673    0]\n",
      " [1327    0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8150\n",
      "- F1 score: 0.4230\n",
      "- Precision: 0.6817\n",
      "- Recall: 0.3066\n",
      "- Roc Auc Score: 0.6330\n",
      "Confusion Matrix: \n",
      " [[17931   760]\n",
      " [ 3681  1628]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18691\n",
      "           1       0.68      0.31      0.42      5309\n",
      "\n",
      "    accuracy                           0.81     24000\n",
      "   macro avg       0.76      0.63      0.66     24000\n",
      "weighted avg       0.80      0.81      0.79     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8215\n",
      "- F1 score: 0.4494\n",
      "- Precision: 0.7071\n",
      "- Recall: 0.3293\n",
      "- Roc Auc Score: 0.6453\n",
      "Confusion Matrix: \n",
      " [[4492  181]\n",
      " [ 890  437]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.71      0.33      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.65      0.67      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8221\n",
      "- F1 score: 0.4517\n",
      "- Precision: 0.7096\n",
      "- Recall: 0.3313\n",
      "- Roc Auc Score: 0.6464\n",
      "Confusion Matrix: \n",
      " [[17971   720]\n",
      " [ 3550  1759]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89     18691\n",
      "           1       0.71      0.33      0.45      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.77      0.65      0.67     24000\n",
      "weighted avg       0.81      0.82      0.80     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8215\n",
      "- F1 score: 0.4482\n",
      "- Precision: 0.7085\n",
      "- Recall: 0.3278\n",
      "- Roc Auc Score: 0.6448\n",
      "Confusion Matrix: \n",
      " [[4494  179]\n",
      " [ 892  435]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.71      0.33      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.64      0.67      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7887\n",
      "- F1 score: 0.1890\n",
      "- Precision: 0.6261\n",
      "- Recall: 0.1113\n",
      "- Roc Auc Score: 0.5462\n",
      "Confusion Matrix: \n",
      " [[18338   353]\n",
      " [ 4718   591]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     18691\n",
      "           1       0.63      0.11      0.19      5309\n",
      "\n",
      "    accuracy                           0.79     24000\n",
      "   macro avg       0.71      0.55      0.53     24000\n",
      "weighted avg       0.76      0.79      0.73     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7902\n",
      "- F1 score: 0.1996\n",
      "- Precision: 0.6382\n",
      "- Recall: 0.1183\n",
      "- Roc Auc Score: 0.5496\n",
      "Confusion Matrix: \n",
      " [[4584   89]\n",
      " [1170  157]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      4673\n",
      "           1       0.64      0.12      0.20      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.72      0.55      0.54      6000\n",
      "weighted avg       0.76      0.79      0.73      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9938\n",
      "- F1 score: 0.9859\n",
      "- Precision: 0.9960\n",
      "- Recall: 0.9761\n",
      "- Roc Auc Score: 0.9875\n",
      "Confusion Matrix: \n",
      " [[18670    21]\n",
      " [  127  5182]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     18691\n",
      "           1       1.00      0.98      0.99      5309\n",
      "\n",
      "    accuracy                           0.99     24000\n",
      "   macro avg       0.99      0.99      0.99     24000\n",
      "weighted avg       0.99      0.99      0.99     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7307\n",
      "- F1 score: 0.4063\n",
      "- Precision: 0.3964\n",
      "- Recall: 0.4167\n",
      "- Roc Auc Score: 0.6183\n",
      "Confusion Matrix: \n",
      " [[3831  842]\n",
      " [ 774  553]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      4673\n",
      "           1       0.40      0.42      0.41      1327\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.61      0.62      0.62      6000\n",
      "weighted avg       0.74      0.73      0.73      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9938\n",
      "- F1 score: 0.9858\n",
      "- Precision: 0.9929\n",
      "- Recall: 0.9787\n",
      "- Roc Auc Score: 0.9884\n",
      "Confusion Matrix: \n",
      " [[18654    37]\n",
      " [  113  5196]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     18691\n",
      "           1       0.99      0.98      0.99      5309\n",
      "\n",
      "    accuracy                           0.99     24000\n",
      "   macro avg       0.99      0.99      0.99     24000\n",
      "weighted avg       0.99      0.99      0.99     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8150\n",
      "- F1 score: 0.4739\n",
      "- Precision: 0.6386\n",
      "- Recall: 0.3768\n",
      "- Roc Auc Score: 0.6581\n",
      "Confusion Matrix: \n",
      " [[4390  283]\n",
      " [ 827  500]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4673\n",
      "           1       0.64      0.38      0.47      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.66      0.68      6000\n",
      "weighted avg       0.80      0.81      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8247\n",
      "- F1 score: 0.4829\n",
      "- Precision: 0.6950\n",
      "- Recall: 0.3699\n",
      "- Roc Auc Score: 0.6619\n",
      "Confusion Matrix: \n",
      " [[17829   862]\n",
      " [ 3345  1964]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     18691\n",
      "           1       0.69      0.37      0.48      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.77      0.66      0.69     24000\n",
      "weighted avg       0.81      0.82      0.80     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8248\n",
      "- F1 score: 0.4825\n",
      "- Precision: 0.6960\n",
      "- Recall: 0.3693\n",
      "- Roc Auc Score: 0.6617\n",
      "Confusion Matrix: \n",
      " [[4459  214]\n",
      " [ 837  490]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.70      0.37      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.66      0.69      6000\n",
      "weighted avg       0.81      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8160\n",
      "- F1 score: 0.4230\n",
      "- Precision: 0.6901\n",
      "- Recall: 0.3050\n",
      "- Roc Auc Score: 0.6330\n",
      "Confusion Matrix: \n",
      " [[17964   727]\n",
      " [ 3690  1619]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     18691\n",
      "           1       0.69      0.30      0.42      5309\n",
      "\n",
      "    accuracy                           0.82     24000\n",
      "   macro avg       0.76      0.63      0.66     24000\n",
      "weighted avg       0.80      0.82      0.79     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8200\n",
      "- F1 score: 0.4346\n",
      "- Precision: 0.7118\n",
      "- Recall: 0.3127\n",
      "- Roc Auc Score: 0.6384\n",
      "Confusion Matrix: \n",
      " [[4505  168]\n",
      " [ 912  415]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.71      0.31      0.43      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.64      0.66      6000\n",
      "weighted avg       0.81      0.82      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9938\n",
      "- F1 score: 0.9859\n",
      "- Precision: 0.9960\n",
      "- Recall: 0.9761\n",
      "- Roc Auc Score: 0.9875\n",
      "Confusion Matrix: \n",
      " [[18670    21]\n",
      " [  127  5182]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     18691\n",
      "           1       1.00      0.98      0.99      5309\n",
      "\n",
      "    accuracy                           0.99     24000\n",
      "   macro avg       0.99      0.99      0.99     24000\n",
      "weighted avg       0.99      0.99      0.99     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7977\n",
      "- F1 score: 0.4482\n",
      "- Precision: 0.5647\n",
      "- Recall: 0.3715\n",
      "- Roc Auc Score: 0.6451\n",
      "Confusion Matrix: \n",
      " [[4293  380]\n",
      " [ 834  493]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      4673\n",
      "           1       0.56      0.37      0.45      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.70      0.65      0.66      6000\n",
      "weighted avg       0.78      0.80      0.78      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8647\n",
      "- F1 score: 0.6057\n",
      "- Precision: 0.8518\n",
      "- Recall: 0.4700\n",
      "- Roc Auc Score: 0.7234\n",
      "Confusion Matrix: \n",
      " [[18257   434]\n",
      " [ 2814  2495]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     18691\n",
      "           1       0.85      0.47      0.61      5309\n",
      "\n",
      "    accuracy                           0.86     24000\n",
      "   macro avg       0.86      0.72      0.76     24000\n",
      "weighted avg       0.86      0.86      0.85     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8210\n",
      "- F1 score: 0.4751\n",
      "- Precision: 0.6759\n",
      "- Recall: 0.3662\n",
      "- Roc Auc Score: 0.6582\n",
      "Confusion Matrix: \n",
      " [[4440  233]\n",
      " [ 841  486]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      4673\n",
      "           1       0.68      0.37      0.48      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.66      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC_score</th>\n",
       "      <th>Train_ROC_AUC_score</th>\n",
       "      <th>Train_presicion</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.824708</td>\n",
       "      <td>0.824833</td>\n",
       "      <td>0.482852</td>\n",
       "      <td>0.482521</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>0.661910</td>\n",
       "      <td>0.694975</td>\n",
       "      <td>0.696023</td>\n",
       "      <td>0.369938</td>\n",
       "      <td>0.369254</td>\n",
       "      <td>0.407518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>0.475073</td>\n",
       "      <td>0.658189</td>\n",
       "      <td>0.723368</td>\n",
       "      <td>0.851827</td>\n",
       "      <td>0.675939</td>\n",
       "      <td>0.469957</td>\n",
       "      <td>0.366240</td>\n",
       "      <td>0.403186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.985771</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>0.658115</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.992929</td>\n",
       "      <td>0.638570</td>\n",
       "      <td>0.978715</td>\n",
       "      <td>0.376790</td>\n",
       "      <td>0.410442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.814958</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>0.423022</td>\n",
       "      <td>0.449357</td>\n",
       "      <td>0.645291</td>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.681742</td>\n",
       "      <td>0.707120</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>0.368714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra tree</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.797667</td>\n",
       "      <td>0.985921</td>\n",
       "      <td>0.448182</td>\n",
       "      <td>0.645098</td>\n",
       "      <td>0.987477</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.564719</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.371515</td>\n",
       "      <td>0.398803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>0.451721</td>\n",
       "      <td>0.448223</td>\n",
       "      <td>0.644751</td>\n",
       "      <td>0.646401</td>\n",
       "      <td>0.709560</td>\n",
       "      <td>0.708469</td>\n",
       "      <td>0.331324</td>\n",
       "      <td>0.327807</td>\n",
       "      <td>0.367275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.815958</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.422992</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.638392</td>\n",
       "      <td>0.633029</td>\n",
       "      <td>0.690111</td>\n",
       "      <td>0.711835</td>\n",
       "      <td>0.304954</td>\n",
       "      <td>0.312735</td>\n",
       "      <td>0.352232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.730667</td>\n",
       "      <td>0.985921</td>\n",
       "      <td>0.406319</td>\n",
       "      <td>0.618273</td>\n",
       "      <td>0.987477</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.396416</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.416729</td>\n",
       "      <td>0.412502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.788708</td>\n",
       "      <td>0.790167</td>\n",
       "      <td>0.189029</td>\n",
       "      <td>0.199619</td>\n",
       "      <td>0.549633</td>\n",
       "      <td>0.546217</td>\n",
       "      <td>0.626059</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.111320</td>\n",
       "      <td>0.118312</td>\n",
       "      <td>0.141340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Classifier</td>\n",
       "      <td>0.778792</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "6       Gradient Boost        0.824708       0.824833  0.482852  0.482521   \n",
       "9              XGBoost        0.864667       0.821000  0.605730  0.475073   \n",
       "5        Random Forest        0.993750       0.815000  0.985771  0.473934   \n",
       "1  Logistic Regression        0.814958       0.821500  0.423022  0.449357   \n",
       "8           Extra tree        0.993833       0.797667  0.985921  0.448182   \n",
       "2                  SVM        0.822083       0.821500  0.451721  0.448223   \n",
       "7             Adaboost        0.815958       0.820000  0.422992  0.434555   \n",
       "4        Decision Tree        0.993833       0.730667  0.985921  0.406319   \n",
       "3          Naive Bayes        0.788708       0.790167  0.189029  0.199619   \n",
       "0  Baseline Classifier        0.778792       0.778833  0.000000  0.000000   \n",
       "\n",
       "   Test_ROC_AUC_score  Train_ROC_AUC_score  Train_presicion  Test_precision  \\\n",
       "6            0.661729             0.661910         0.694975        0.696023   \n",
       "9            0.658189             0.723368         0.851827        0.675939   \n",
       "5            0.658115             0.988368         0.992929        0.638570   \n",
       "1            0.645291             0.632994         0.681742        0.707120   \n",
       "8            0.645098             0.987477         0.995964        0.564719   \n",
       "2            0.644751             0.646401         0.709560        0.708469   \n",
       "7            0.638392             0.633029         0.690111        0.711835   \n",
       "4            0.618273             0.987477         0.995964        0.396416   \n",
       "3            0.549633             0.546217         0.626059        0.638211   \n",
       "0            0.500000             0.500000         0.000000        0.000000   \n",
       "\n",
       "   Train_recall  Test_recall  F2-Score  \n",
       "6      0.369938     0.369254  0.407518  \n",
       "9      0.469957     0.366240  0.403186  \n",
       "5      0.978715     0.376790  0.410442  \n",
       "1      0.306649     0.329314  0.368714  \n",
       "8      0.976078     0.371515  0.398803  \n",
       "2      0.331324     0.327807  0.367275  \n",
       "7      0.304954     0.312735  0.352232  \n",
       "4      0.976078     0.416729  0.412502  \n",
       "3      0.111320     0.118312  0.141340  \n",
       "0      0.000000     0.000000  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fs1_df = X_train_transformed_df[feature_importance['features']]\n",
    "x_test_fs1_df = x_test_transformed_df[feature_importance['features']]\n",
    "report3 = evaluate_models(X_train_fs1_df, y_train, x_test_fs1_df, y_test, models)\n",
    "report3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455976d",
   "metadata": {},
   "source": [
    "#### Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ee73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5000\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[17714     0]\n",
      " [17714     0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     17714\n",
      "           1       0.00      0.00      0.00     17714\n",
      "\n",
      "    accuracy                           0.50     35428\n",
      "   macro avg       0.25      0.50      0.33     35428\n",
      "weighted avg       0.25      0.50      0.33     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Precision: 0.0000\n",
      "- Recall: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[4673    0]\n",
      " [1327    0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7008\n",
      "- F1 score: 0.6351\n",
      "- Precision: 0.8137\n",
      "- Recall: 0.5208\n",
      "- Roc Auc Score: 0.7008\n",
      "Confusion Matrix: \n",
      " [[15601  2113]\n",
      " [ 8488  9226]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75     17714\n",
      "           1       0.81      0.52      0.64     17714\n",
      "\n",
      "    accuracy                           0.70     35428\n",
      "   macro avg       0.73      0.70      0.69     35428\n",
      "weighted avg       0.73      0.70      0.69     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7997\n",
      "- F1 score: 0.5348\n",
      "- Precision: 0.5497\n",
      "- Recall: 0.5207\n",
      "- Roc Auc Score: 0.6998\n",
      "Confusion Matrix: \n",
      " [[4107  566]\n",
      " [ 636  691]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4673\n",
      "           1       0.55      0.52      0.53      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.71      0.70      0.70      6000\n",
      "weighted avg       0.80      0.80      0.80      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7155\n",
      "- F1 score: 0.6675\n",
      "- Precision: 0.8032\n",
      "- Recall: 0.5710\n",
      "- Roc Auc Score: 0.7155\n",
      "Confusion Matrix: \n",
      " [[15235  2479]\n",
      " [ 7599 10115]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75     17714\n",
      "           1       0.80      0.57      0.67     17714\n",
      "\n",
      "    accuracy                           0.72     35428\n",
      "   macro avg       0.74      0.72      0.71     35428\n",
      "weighted avg       0.74      0.72      0.71     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7793\n",
      "- F1 score: 0.5220\n",
      "- Precision: 0.5010\n",
      "- Recall: 0.5448\n",
      "- Roc Auc Score: 0.6954\n",
      "Confusion Matrix: \n",
      " [[3953  720]\n",
      " [ 604  723]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      4673\n",
      "           1       0.50      0.54      0.52      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.79      0.78      0.78      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5793\n",
      "- F1 score: 0.3037\n",
      "- Precision: 0.8806\n",
      "- Recall: 0.1835\n",
      "- Roc Auc Score: 0.5793\n",
      "Confusion Matrix: \n",
      " [[17273   441]\n",
      " [14463  3251]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70     17714\n",
      "           1       0.88      0.18      0.30     17714\n",
      "\n",
      "    accuracy                           0.58     35428\n",
      "   macro avg       0.71      0.58      0.50     35428\n",
      "weighted avg       0.71      0.58      0.50     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8002\n",
      "- F1 score: 0.2935\n",
      "- Precision: 0.6730\n",
      "- Recall: 0.1876\n",
      "- Roc Auc Score: 0.5809\n",
      "Confusion Matrix: \n",
      " [[4552  121]\n",
      " [1078  249]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      4673\n",
      "           1       0.67      0.19      0.29      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.74      0.58      0.59      6000\n",
      "weighted avg       0.78      0.80      0.75      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9950\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9953\n",
      "- Recall: 0.9947\n",
      "- Roc Auc Score: 0.9950\n",
      "Confusion Matrix: \n",
      " [[17630    84]\n",
      " [   94 17620]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     17714\n",
      "           1       1.00      0.99      0.99     17714\n",
      "\n",
      "    accuracy                           0.99     35428\n",
      "   macro avg       0.99      0.99      0.99     35428\n",
      "weighted avg       0.99      0.99      0.99     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6837\n",
      "- F1 score: 0.4005\n",
      "- Precision: 0.3448\n",
      "- Recall: 0.4778\n",
      "- Roc Auc Score: 0.6100\n",
      "Confusion Matrix: \n",
      " [[3468 1205]\n",
      " [ 693  634]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.79      4673\n",
      "           1       0.34      0.48      0.40      1327\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.59      0.61      0.59      6000\n",
      "weighted avg       0.73      0.68      0.70      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9949\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9941\n",
      "- Recall: 0.9958\n",
      "- Roc Auc Score: 0.9949\n",
      "Confusion Matrix: \n",
      " [[17609   105]\n",
      " [   74 17640]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17714\n",
      "           1       0.99      1.00      0.99     17714\n",
      "\n",
      "    accuracy                           0.99     35428\n",
      "   macro avg       0.99      0.99      0.99     35428\n",
      "weighted avg       0.99      0.99      0.99     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7638\n",
      "- F1 score: 0.4811\n",
      "- Precision: 0.4679\n",
      "- Recall: 0.4951\n",
      "- Roc Auc Score: 0.6676\n",
      "Confusion Matrix: \n",
      " [[3926  747]\n",
      " [ 670  657]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      4673\n",
      "           1       0.47      0.50      0.48      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.66      0.67      0.66      6000\n",
      "weighted avg       0.77      0.76      0.77      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7680\n",
      "- F1 score: 0.7472\n",
      "- Precision: 0.8207\n",
      "- Recall: 0.6858\n",
      "- Roc Auc Score: 0.7680\n",
      "Confusion Matrix: \n",
      " [[15059  2655]\n",
      " [ 5565 12149]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79     17714\n",
      "           1       0.82      0.69      0.75     17714\n",
      "\n",
      "    accuracy                           0.77     35428\n",
      "   macro avg       0.78      0.77      0.77     35428\n",
      "weighted avg       0.78      0.77      0.77     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7820\n",
      "- F1 score: 0.5398\n",
      "- Precision: 0.5063\n",
      "- Recall: 0.5780\n",
      "- Roc Auc Score: 0.7090\n",
      "Confusion Matrix: \n",
      " [[3925  748]\n",
      " [ 560  767]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      4673\n",
      "           1       0.51      0.58      0.54      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.69      0.71      0.70      6000\n",
      "weighted avg       0.79      0.78      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7311\n",
      "- F1 score: 0.7033\n",
      "- Precision: 0.7844\n",
      "- Recall: 0.6375\n",
      "- Roc Auc Score: 0.7311\n",
      "Confusion Matrix: \n",
      " [[14610  3104]\n",
      " [ 6422 11292]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75     17714\n",
      "           1       0.78      0.64      0.70     17714\n",
      "\n",
      "    accuracy                           0.73     35428\n",
      "   macro avg       0.74      0.73      0.73     35428\n",
      "weighted avg       0.74      0.73      0.73     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7655\n",
      "- F1 score: 0.5239\n",
      "- Precision: 0.4754\n",
      "- Recall: 0.5833\n",
      "- Roc Auc Score: 0.7003\n",
      "Confusion Matrix: \n",
      " [[3819  854]\n",
      " [ 553  774]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      4673\n",
      "           1       0.48      0.58      0.52      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.70      0.68      6000\n",
      "weighted avg       0.79      0.77      0.77      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9950\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9953\n",
      "- Recall: 0.9947\n",
      "- Roc Auc Score: 0.9950\n",
      "Confusion Matrix: \n",
      " [[17630    84]\n",
      " [   94 17620]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     17714\n",
      "           1       1.00      0.99      0.99     17714\n",
      "\n",
      "    accuracy                           0.99     35428\n",
      "   macro avg       0.99      0.99      0.99     35428\n",
      "weighted avg       0.99      0.99      0.99     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7612\n",
      "- F1 score: 0.4631\n",
      "- Precision: 0.4605\n",
      "- Recall: 0.4657\n",
      "- Roc Auc Score: 0.6554\n",
      "Confusion Matrix: \n",
      " [[3949  724]\n",
      " [ 709  618]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4673\n",
      "           1       0.46      0.47      0.46      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.65      0.66      0.65      6000\n",
      "weighted avg       0.76      0.76      0.76      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8697\n",
      "- F1 score: 0.8614\n",
      "- Precision: 0.9203\n",
      "- Recall: 0.8095\n",
      "- Roc Auc Score: 0.8697\n",
      "Confusion Matrix: \n",
      " [[16473  1241]\n",
      " [ 3375 14339]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88     17714\n",
      "           1       0.92      0.81      0.86     17714\n",
      "\n",
      "    accuracy                           0.87     35428\n",
      "   macro avg       0.88      0.87      0.87     35428\n",
      "weighted avg       0.88      0.87      0.87     35428\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7982\n",
      "- F1 score: 0.5115\n",
      "- Precision: 0.5503\n",
      "- Recall: 0.4778\n",
      "- Roc Auc Score: 0.6835\n",
      "Confusion Matrix: \n",
      " [[4155  518]\n",
      " [ 693  634]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4673\n",
      "           1       0.55      0.48      0.51      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.70      0.68      0.69      6000\n",
      "weighted avg       0.79      0.80      0.79      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC_score</th>\n",
       "      <th>Train_ROC_AUC_score</th>\n",
       "      <th>Train_presicion</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.767980</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.747217</td>\n",
       "      <td>0.539761</td>\n",
       "      <td>0.708964</td>\n",
       "      <td>0.767980</td>\n",
       "      <td>0.820657</td>\n",
       "      <td>0.506271</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.577995</td>\n",
       "      <td>0.562069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.765500</td>\n",
       "      <td>0.703332</td>\n",
       "      <td>0.523858</td>\n",
       "      <td>0.700259</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.784385</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.637462</td>\n",
       "      <td>0.583271</td>\n",
       "      <td>0.557958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>0.799667</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.699801</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>0.813652</td>\n",
       "      <td>0.549722</td>\n",
       "      <td>0.520831</td>\n",
       "      <td>0.520723</td>\n",
       "      <td>0.526276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.779333</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.522022</td>\n",
       "      <td>0.695381</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.803160</td>\n",
       "      <td>0.501040</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.544838</td>\n",
       "      <td>0.535476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>0.798167</td>\n",
       "      <td>0.861356</td>\n",
       "      <td>0.511497</td>\n",
       "      <td>0.683460</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>0.920347</td>\n",
       "      <td>0.550347</td>\n",
       "      <td>0.809473</td>\n",
       "      <td>0.477769</td>\n",
       "      <td>0.490712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.994947</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.994952</td>\n",
       "      <td>0.481142</td>\n",
       "      <td>0.667624</td>\n",
       "      <td>0.994947</td>\n",
       "      <td>0.994083</td>\n",
       "      <td>0.467949</td>\n",
       "      <td>0.995823</td>\n",
       "      <td>0.495102</td>\n",
       "      <td>0.489422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra tree</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.761167</td>\n",
       "      <td>0.994974</td>\n",
       "      <td>0.463095</td>\n",
       "      <td>0.655390</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.460507</td>\n",
       "      <td>0.994693</td>\n",
       "      <td>0.465712</td>\n",
       "      <td>0.464662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.683667</td>\n",
       "      <td>0.994974</td>\n",
       "      <td>0.400505</td>\n",
       "      <td>0.609953</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.344753</td>\n",
       "      <td>0.994693</td>\n",
       "      <td>0.477769</td>\n",
       "      <td>0.443543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.579316</td>\n",
       "      <td>0.800167</td>\n",
       "      <td>0.303747</td>\n",
       "      <td>0.293459</td>\n",
       "      <td>0.580874</td>\n",
       "      <td>0.579316</td>\n",
       "      <td>0.880553</td>\n",
       "      <td>0.672973</td>\n",
       "      <td>0.183527</td>\n",
       "      <td>0.187641</td>\n",
       "      <td>0.219267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Classifier</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "6       Gradient Boost        0.767980       0.782000  0.747217  0.539761   \n",
       "7             Adaboost        0.731117       0.765500  0.703332  0.523858   \n",
       "1  Logistic Regression        0.700773       0.799667  0.635115  0.534830   \n",
       "2                  SVM        0.715536       0.779333  0.667481  0.522022   \n",
       "9              XGBoost        0.869708       0.798167  0.861356  0.511497   \n",
       "5        Random Forest        0.994947       0.763833  0.994952  0.481142   \n",
       "8           Extra tree        0.994976       0.761167  0.994974  0.463095   \n",
       "4        Decision Tree        0.994976       0.683667  0.994974  0.400505   \n",
       "3          Naive Bayes        0.579316       0.800167  0.303747  0.293459   \n",
       "0  Baseline Classifier        0.500000       0.778833  0.000000  0.000000   \n",
       "\n",
       "   Test_ROC_AUC_score  Train_ROC_AUC_score  Train_presicion  Test_precision  \\\n",
       "6            0.708964             0.767980         0.820657        0.506271   \n",
       "7            0.700259             0.731117         0.784385        0.475430   \n",
       "1            0.699801             0.700773         0.813652        0.549722   \n",
       "2            0.695381             0.715536         0.803160        0.501040   \n",
       "9            0.683460             0.869708         0.920347        0.550347   \n",
       "5            0.667624             0.994947         0.994083        0.467949   \n",
       "8            0.655390             0.994976         0.995255        0.460507   \n",
       "4            0.609953             0.994976         0.995255        0.344753   \n",
       "3            0.580874             0.579316         0.880553        0.672973   \n",
       "0            0.500000             0.500000         0.000000        0.000000   \n",
       "\n",
       "   Train_recall  Test_recall  F2-Score  \n",
       "6      0.685842     0.577995  0.562069  \n",
       "7      0.637462     0.583271  0.557958  \n",
       "1      0.520831     0.520723  0.526276  \n",
       "2      0.571017     0.544838  0.535476  \n",
       "9      0.809473     0.477769  0.490712  \n",
       "5      0.995823     0.495102  0.489422  \n",
       "8      0.994693     0.465712  0.464662  \n",
       "4      0.994693     0.477769  0.443543  \n",
       "3      0.183527     0.187641  0.219267  \n",
       "0      0.000000     0.000000  0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='auto',n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_train_transformed_sampled, y_train_sampled = smt.fit_resample(X_train_fs1_df, y_train)\n",
    "report4 = evaluate_models(X_train_transformed_sampled, y_train_sampled, x_test_fs1_df, y_test, models)\n",
    "report4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d384d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC_score</th>\n",
       "      <th>Train_ROC_AUC_score</th>\n",
       "      <th>Train_presicion</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.767980</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.747217</td>\n",
       "      <td>0.539761</td>\n",
       "      <td>0.708964</td>\n",
       "      <td>0.767980</td>\n",
       "      <td>0.820657</td>\n",
       "      <td>0.506271</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.577995</td>\n",
       "      <td>0.562069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.765500</td>\n",
       "      <td>0.703332</td>\n",
       "      <td>0.523858</td>\n",
       "      <td>0.700259</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.784385</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>0.637462</td>\n",
       "      <td>0.583271</td>\n",
       "      <td>0.557958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>0.799667</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.699801</td>\n",
       "      <td>0.700773</td>\n",
       "      <td>0.813652</td>\n",
       "      <td>0.549722</td>\n",
       "      <td>0.520831</td>\n",
       "      <td>0.520723</td>\n",
       "      <td>0.526276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.779333</td>\n",
       "      <td>0.667481</td>\n",
       "      <td>0.522022</td>\n",
       "      <td>0.695381</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.803160</td>\n",
       "      <td>0.501040</td>\n",
       "      <td>0.571017</td>\n",
       "      <td>0.544838</td>\n",
       "      <td>0.535476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>0.798167</td>\n",
       "      <td>0.861356</td>\n",
       "      <td>0.511497</td>\n",
       "      <td>0.683460</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>0.920347</td>\n",
       "      <td>0.550347</td>\n",
       "      <td>0.809473</td>\n",
       "      <td>0.477769</td>\n",
       "      <td>0.490712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "6       Gradient Boost        0.767980       0.782000  0.747217  0.539761   \n",
       "7             Adaboost        0.731117       0.765500  0.703332  0.523858   \n",
       "1  Logistic Regression        0.700773       0.799667  0.635115  0.534830   \n",
       "2                  SVM        0.715536       0.779333  0.667481  0.522022   \n",
       "9              XGBoost        0.869708       0.798167  0.861356  0.511497   \n",
       "\n",
       "   Test_ROC_AUC_score  Train_ROC_AUC_score  Train_presicion  Test_precision  \\\n",
       "6            0.708964             0.767980         0.820657        0.506271   \n",
       "7            0.700259             0.731117         0.784385        0.475430   \n",
       "1            0.699801             0.700773         0.813652        0.549722   \n",
       "2            0.695381             0.715536         0.803160        0.501040   \n",
       "9            0.683460             0.869708         0.920347        0.550347   \n",
       "\n",
       "   Train_recall  Test_recall  F2-Score  \n",
       "6      0.685842     0.577995  0.562069  \n",
       "7      0.637462     0.583271  0.557958  \n",
       "1      0.520831     0.520723  0.526276  \n",
       "2      0.571017     0.544838  0.535476  \n",
       "9      0.809473     0.477769  0.490712  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report4[report4['Test_F1']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4da29e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = report4[report4['Test_F1']>0.5]\n",
    "plt.plot('Model Name', 'Test_F1', data=data)\n",
    "plt.plot('Model Name', 'Train_F1', data=data)\n",
    "plt.plot('Model Name', 'F2-Score', data=data)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7068a",
   "metadata": {},
   "source": [
    "#### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c037dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#logistic regression with hyperparameter tuning\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2', 'elasticnet'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter':[100, 110, 120, 130, 140],\n",
    "          'class_weight': ['balanced']}\n",
    "skf= StratifiedKFold(n_splits=10)\n",
    "lr_hyper = GridSearchCV(lr, param_grid=params, n_jobs=-1, cv=skf)\n",
    "lr_hyper.fit(X_train_fs1_df, y_train)\n",
    "y_pred = lr_hyper.predict(x_test_fs1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "720620a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[4115  558]\n",
      " [ 639  688]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4673\n",
      "           1       0.55      0.52      0.53      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.71      0.70      0.70      6000\n",
      "weighted avg       0.80      0.80      0.80      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_confusion_matrix(y_test, y_pred, lr_hyper.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25a904f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_hyper.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d3f0f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81d480b4",
   "metadata": {},
   "source": [
    "####  Model interpretability using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61544bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceca9585",
   "metadata": {},
   "source": [
    "#### Evaluate models based on F1-Score and AUC ROC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67752e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_roc_auc_curve(y_true, y_pred, model, x_test, name):\n",
    "    #plot Roc-auc curve\n",
    "    model_roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    fpr, tpr, threshold = roc_curve(y_true, model.predict_proba(x_test)[:,1])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    #following code adapted from roc_auc_curve scikit-learn documentation\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='{0} ROC curve (area = {1:.2f})' .format(name, model_roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d244e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(class_weight='balanced',)\n",
    "#lr.fit(X_train_transformed, y_train)\n",
    "#y_pred = lr.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(class_weight='balanced', probability=True)\n",
    "#svm.fit(X_train_transformed, y_train)\n",
    "#y_pred_svm = svm.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_roc_auc_lr = roc_auc_score(y_test, y_pred)\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, lr.predict_proba(x_test_transformed)[:,1])\n",
    "model_roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "fpr_svm, tpr_svm, threshold_svm = roc_curve(y_test, svm.predict_proba(x_test_transformed)[:,1])\n",
    "plt.figure(figsize=(10, 5))\n",
    "#following code adapted from roc_auc_curve scikit-learn documentation\n",
    "lw = 2\n",
    "plt.plot(fpr_lr, tpr_lr, color='darkorange',\n",
    "           lw=lw, label='{0} ROC curve (area = {1:.2f})' .format(\"Logistic Regression\", model_roc_auc_lr))\n",
    "plt.plot(fpr_svm, tpr_svm, color='lightblue',\n",
    "           lw=lw, label='{0} ROC curve (area = {1:.2f})' .format(\"SVM\", model_roc_auc_svm))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#plot_roc_auc_curve(y_test, y_pred, lr, x_test_transformed, name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627173d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#logistic regression with hyperparameter tuning\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter':[100, 110, 120, 130, 140],\n",
    "          'class_weight': ['balanced']}\n",
    "skf= StratifiedKFold(n_splits=10)\n",
    "lr_hyper = GridSearchCV(lr, param_grid=params, n_jobs=-1, cv=skf)\n",
    "lr_hyper.fit(X_train_transformed, y_train)\n",
    "y_pred = lr_hyper.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_confusion_matrix(y_test, y_pred, lr_hyper.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e403136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(fbeta_score(y_test, y_pred, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_hyper.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136ea5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9059ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
