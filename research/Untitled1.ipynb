{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489561c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautosklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X, y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "    automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "    automl.fit(X_train, y_train)\n",
    "    y_hat = automl.predict(X_test)\n",
    "    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085e1011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95aa0fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn\n",
      "  Using cached auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-h8t86_0q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-h8t86_0q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-h8t86_0q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 480, in run_setup\n",
      "      super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-h8t86_0q\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 10, in <module>\n",
      "  ValueError: Detected unsupported operating system: win32. Please check the compability information of auto-sklearn: https://automl.github.io/auto-sklearn/master/installation.html#windows-osx-compatibility\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d1fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-ml\n",
      "  Downloading auto_ml-2.9.10-py2.py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 0.0/71.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/71.6 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/71.6 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 30.7/71.6 kB 325.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 71.6/71.6 kB 490.9 kB/s eta 0:00:00\n",
      "Collecting dill<0.3,>=0.2.5 (from auto-ml)\n",
      "  Downloading dill-0.2.9.tar.gz (150 kB)\n",
      "     ---------------------------------------- 0.0/150.7 kB ? eta -:--:--\n",
      "     ------------------------------ ------- 122.9/150.7 kB 3.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 150.7/150.7 kB 3.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting h5py<3.0,>=2.7.0 (from auto-ml)\n",
      "  Downloading h5py-2.10.0.tar.gz (301 kB)\n",
      "     ---------------------------------------- 0.0/301.1 kB ? eta -:--:--\n",
      "     -------------------------------------  297.0/301.1 kB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 301.1/301.1 kB 9.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lightgbm<2.1,>=2.0.11 (from auto-ml)\n",
      "  Downloading lightgbm-2.0.12-py2.py3-none-win_amd64.whl (431 kB)\n",
      "     ---------------------------------------- 0.0/431.9 kB ? eta -:--:--\n",
      "     ------------------------------------  430.1/431.9 kB 13.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 431.9/431.9 kB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.11.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from auto-ml) (1.26.2)\n",
      "Collecting pandas<1.0,>=0.18.0 (from auto-ml)\n",
      "  Downloading pandas-0.25.3.tar.gz (12.6 MB)\n",
      "     ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.4/12.6 MB 11.2 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.9/12.6 MB 9.5 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.4/12.6 MB 9.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.0/12.6 MB 9.0 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.5/12.6 MB 8.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.6 MB 8.9 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.5/12.6 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.0/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.5/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 4.9/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.5/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.9/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.6/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.6/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.2/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.2/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.6/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.8/12.6 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.4/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.6/12.6 MB 8.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pathos<0.3.0,>=0.2.1 (from auto-ml)\n",
      "  Downloading pathos-0.2.9-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.9/76.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0,>=2.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from auto-ml) (2.8.2)\n",
      "Collecting scikit-learn<1.0,>=0.18.1 (from auto-ml)\n",
      "  Downloading scikit-learn-0.24.2.tar.gz (7.5 MB)\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/7.5 MB 7.6 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.8/7.5 MB 8.7 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.2/7.5 MB 8.2 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.5/7.5 MB 8.8 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.9/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.2/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.6/7.5 MB 8.6 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.9/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 3.3/7.5 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.7/7.5 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 4.3/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.8/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 5.1/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.7/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 6.3/7.5 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.9/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.5/7.5 MB 7.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [62 lines of output]\n",
      "  <string>:17: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  Partial import of sklearn during the build process.\n",
      "  <string>:116: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 366, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 480, in run_setup\n",
      "      super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 301, in <module>\n",
      "    File \"<string>\", line 297, in setup_package\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 136, in setup\n",
      "      config = configuration()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "    File \"<string>\", line 188, in configuration\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "      config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "      config = self._get_configuration_from_setup_py(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "      config = setup_module.configuration(*args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-smoosqka\\scikit-learn_7d6ac6a01a5b44d3ab06cd4c9f59f093\\sklearn\\setup.py\", line 83, in configuration\n",
      "      cythonize_extensions(top_path, config)\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-smoosqka\\scikit-learn_7d6ac6a01a5b44d3ab06cd4c9f59f093\\sklearn\\_build_utils\\__init__.py\", line 45, in cythonize_extensions\n",
      "      basic_check_build()\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-smoosqka\\scikit-learn_7d6ac6a01a5b44d3ab06cd4c9f59f093\\sklearn\\_build_utils\\pre_build_helpers.py\", line 106, in basic_check_build\n",
      "      compile_test_program(code)\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-smoosqka\\scikit-learn_7d6ac6a01a5b44d3ab06cd4c9f59f093\\sklearn\\_build_utils\\pre_build_helpers.py\", line 66, in compile_test_program\n",
      "      ccompiler.compile(['test_program.c'], output_dir='objects',\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 233, in msvc14_get_vc_env\n",
      "      return _msvc14_get_vc_env(plat_spec)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-build-env-3chobyf2\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 190, in _msvc14_get_vc_env\n",
      "      raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install auto-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc60b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, fbeta_score, precision_score, \\\n",
    "                            recall_score, roc_auc_score, classification_report, f1_score, roc_curve\n",
    "                            \n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e732f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "#load downloaded file\n",
    "INPUT_PATH = r\"C:\\Users\\User\\Desktop\\portfolio\\cc_defaulter_prediction\\artifacts\\data_ingestion\\CreditCardClients.xls\"\n",
    "df = pd.read_excel(INPUT_PATH, header=1)\n",
    "#drop id colum\n",
    "df.drop(columns='ID', inplace=True)\n",
    "#rename columns for convenience\n",
    "df.rename(columns = {'PAY_0': 'PAY_1', 'default payment next month': 'Default'}, inplace=True)\n",
    "\n",
    "#lowering column names \n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "#split the data based on class label\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=33)\n",
    "# Use the split method to get the indices for training and testing\n",
    "strat_train_set = None\n",
    "strat_test_set = None\n",
    "for train_idx, test_idx in split.split(df, df.iloc[:,-1]):\n",
    "    df_train = df.loc[train_idx]\n",
    "    df_test = df.loc[test_idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5e6cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['limit_bal', 'sex', 'education', 'marriage', 'age', 'pay_1', 'pay_2',\n",
       "       'pay_3', 'pay_4', 'pay_5', 'pay_6', 'bill_amt1', 'bill_amt2',\n",
       "       'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6', 'pay_amt1',\n",
       "       'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322107a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(TransformerMixin):\n",
    "    \n",
    "    '''\n",
    "    Upon calling fit_transform or transform method this column generates new dataframe columns\n",
    "    '''\n",
    "    def __init__(self):\n",
    "      \n",
    "        try:\n",
    "            self.bill_amt1_ix = \"bill_amt1\"\n",
    "            self.bill_amt2_ix = \"bill_amt2\"\n",
    "            self.bill_amt3_ix = \"bill_amt3\"\n",
    "            self.bill_amt4_ix = \"bill_amt4\"\n",
    "            self.bill_amt5_ix = \"bill_amt5\"\n",
    "            self.bill_amt6_ix = \"bill_amt6\"\n",
    "            self.limit_bal_ix = \"limit_bal\"\n",
    "            self.pay_amt1_ix = \"pay_amt1\"\n",
    "            self.pay_amt2_ix = \"pay_amt2\"\n",
    "            self.pay_amt3_ix = \"pay_amt3\"\n",
    "            self.pay_amt4_ix = \"pay_amt4\"\n",
    "            self.pay_amt5_ix = \"pay_amt5\"\n",
    "            self.pay_amt6_ix = \"pay_amt6\"\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "            X['leverage_1'] = X[self.bill_amt1_ix]/X[self.limit_bal_ix]   \n",
    "            X['leverage_2'] = X[self.bill_amt2_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_3'] = X[self.bill_amt3_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_4'] = X[self.bill_amt4_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_5'] = X[self.bill_amt5_ix]/X[self.limit_bal_ix]\n",
    "            X['leverage_6'] = X[self.bill_amt6_ix]/X[self.limit_bal_ix]\n",
    "\n",
    "            X['bill_to_pay1'] = X[self.bill_amt1_ix]/(X[self.pay_amt1_ix]+1)   \n",
    "            X['bill_to_pay2'] = X[self.bill_amt2_ix]/(X[self.pay_amt2_ix]+1)\n",
    "            X['bill_to_pay3'] = X[self.bill_amt3_ix]/(X[self.pay_amt3_ix]+1)\n",
    "            X['bill_to_pay4'] = X[self.bill_amt4_ix]/(X[self.pay_amt4_ix]+1)\n",
    "            X['bill_to_pay5'] = X[self.bill_amt5_ix]/(X[self.pay_amt5_ix]+1)\n",
    "            X['bill_to_pay6'] = X[self.bill_amt6_ix]/(X[self.pay_amt6_ix]+1)\n",
    "            \n",
    "            X['overdraft'] = np.where(   (X[self.bill_amt1_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt2_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt3_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt4_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt5_ix]>X[self.limit_bal_ix]) |\n",
    "                                        (X[self.bill_amt6_ix]>X[self.limit_bal_ix]),\n",
    "                                        1, 0                                 \n",
    "                                    )\n",
    "        '''\n",
    "        X['avg_bill_amt'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                     +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/6\n",
    "        X['avg_leverage_ratio'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                       +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/(6*X[self.limit_bal_ix])\n",
    "        X['avg_pay_amt'] = (X[self.pay_amt1_ix]+X[self.pay_amt2_ix]+X[self.pay_amt3_ix] \\\n",
    "                                      +X[self.pay_amt4_ix]+X[self.pay_amt5_ix]+X[self.pay_amt6_ix])/6\n",
    "        X['avg_bill_to_pay'] = (X[self.bill_amt1_ix]+X[self.bill_amt2_ix]+X[self.bill_amt3_ix] \\\n",
    "                                       +X[self.bill_amt4_ix]+X[self.bill_amt5_ix]+X[self.bill_amt6_ix])/ \\\n",
    "                                        ((X[self.pay_amt1_ix]+X[self.pay_amt2_ix]+X[self.pay_amt3_ix] \\\n",
    "                                       +X[self.pay_amt4_ix]+X[self.pay_amt5_ix]+X[self.pay_amt6_ix])+1)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3708380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess1(numeric_features, categorical_features):#, model_name, model):\n",
    "    '''\n",
    "    input: list of numerical features and categorical features\n",
    "    applies transformers on given data\n",
    "    returns: preprocessed object\n",
    "    '''\n",
    "    \n",
    "    # Create transformers\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    feature_generator = FeatureGenerator()\n",
    "    \n",
    "    # Create transformers\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', RobustScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "        # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=[('feature generator', feature_generator),('preprocessor', preprocessor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac5d672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea9bf0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b1ace4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998129917690063"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ea75017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99981299])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d518d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def evaluate_clf(true, predicted):\n",
    "    '''\n",
    "    Input: True values and Predicted values\n",
    "    Returns: Accuracy, F1-Score, Precision, Recall, Roc-auc Score\n",
    "    '''\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted)  # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57170657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print confusion matrix and classification report\n",
    "def display_confusion_matrix(y_true, y_pred, labels):\n",
    "    '''\n",
    "    This function takes y_ture, y_predicted, class labels and returns false positives and false negatives\n",
    "   \n",
    "    '''\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)#, normalize='all')\n",
    "    print(\"Confusion Matrix: \\n\", cm)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_true, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d33c9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "\n",
    "def evaluate_models(X_train, y_train, x_test, y_test, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "   \n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    models_list = []\n",
    "    model_train_accuracy_list = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "    model_test_accuracy_list = []\n",
    "    #train_roc = []\n",
    "    #test_roc =[]\n",
    "    f2_score = []\n",
    "    \n",
    "\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "\n",
    "\n",
    "        # Test set performance\n",
    "        model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        model_train_accuracy_list.append(model_train_accuracy)\n",
    "        model_test_accuracy_list.append(model_test_accuracy)\n",
    "        train_f1.append(model_train_f1)\n",
    "        test_f1.append(model_test_f1)\n",
    "        #train_roc.append(model_train_rocauc_score)\n",
    "        #test_roc.append(model_test_rocauc_score)\n",
    "        f2_score.append(fbeta_score(y_test, y_test_pred, beta=2))\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        #print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        #print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        display_confusion_matrix(y_train, y_train_pred, model.classes_)\n",
    "\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        #print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        #print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        display_confusion_matrix(y_test, y_test_pred, model.classes_)\n",
    "\n",
    "        \n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "    report_data = {\n",
    "        'Model Name': models_list,\n",
    "        'Train Accuracy': model_train_accuracy_list,\n",
    "      #  'Train_ROC_AUC_score': train_roc,\n",
    "        'Test Accuracy': model_test_accuracy_list,\n",
    "        'Train_F1': train_f1,\n",
    "\n",
    "        'Test_F1': test_f1,\n",
    "      #  'Test_ROC_AUC_score': test_roc\n",
    "        'F2-Score':f2_score\n",
    "    }\n",
    "    \n",
    "    report = pd.DataFrame(report_data).sort_values(by=['F2-Score', 'Test_F1'], ascending=False)        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5dc1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of classification models\n",
    "models = {\n",
    "    \"Baseline Classifier\": DummyClassifier(strategy='most_frequent'),\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced'),\n",
    "    \"SVM\": SVC(class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"Gradient Boost\": GradientBoostingClassifier(),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"Extra tree\": ExtraTreesClassifier(class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45d0b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'education', 'marriage','pay_1', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "numeric_cols = ['age','limit_bal', 'bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4', 'bill_amt5', 'bill_amt6', \\\n",
    "                 'pay_amt1', 'pay_amt2', 'pay_amt3', 'pay_amt4', 'pay_amt5', 'pay_amt6']\n",
    "engineered_cols = ['avg_bill_amt', 'avg_leverage_ratio', 'avg_pay_amt', 'avg_bill_to_pay']\n",
    "X_train = df_train.drop('default', axis=1)\n",
    "y_train = df_train['default']\n",
    "\n",
    "x_test=df_test.drop('default', axis=1)\n",
    "y_test=df_test['default']\n",
    "num_cols = numeric_cols+engineered_cols\n",
    "pipeline = preprocess1(num_cols, categorical_features)\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "x_test_transformed = pipeline.transform(x_test)\n",
    "column_names = pipeline[1:].named_steps['preprocessor'].get_feature_names_out()\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed.toarray(), columns = column_names)\n",
    "x_test_transformed_df = pd.DataFrame(x_test_transformed.toarray(), columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c68ec7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 10)\n",
    "X_train_pca = pca.fit_transform(X_train_transformed_df)\n",
    "x_test_pca = pca.transform(x_test_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1bcf519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99812992e-01, 6.36458111e-05, 2.77449392e-05, 2.21015713e-05,\n",
       "       1.95314043e-05, 1.82838242e-05, 1.58649723e-05, 1.09976646e-05,\n",
       "       1.59953663e-06, 9.51366271e-07])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2a68854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[18691     0]\n",
      " [ 5309     0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     18691\n",
      "           1       0.00      0.00      0.00      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.39      0.50      0.44     24000\n",
      "weighted avg       0.61      0.78      0.68     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7788\n",
      "- F1 score: 0.0000\n",
      "- Roc Auc Score: 0.5000\n",
      "Confusion Matrix: \n",
      " [[4673    0]\n",
      " [1327    0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      4673\n",
      "           1       0.00      0.00      0.00      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.61      0.78      0.68      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5567\n",
      "- F1 score: 0.4122\n",
      "- Roc Auc Score: 0.6090\n",
      "Confusion Matrix: \n",
      " [[9629 9062]\n",
      " [1578 3731]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.52      0.64     18691\n",
      "           1       0.29      0.70      0.41      5309\n",
      "\n",
      "    accuracy                           0.56     24000\n",
      "   macro avg       0.58      0.61      0.53     24000\n",
      "weighted avg       0.73      0.56      0.59     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.5553\n",
      "- F1 score: 0.4076\n",
      "- Roc Auc Score: 0.6042\n",
      "Confusion Matrix: \n",
      " [[2414 2259]\n",
      " [ 409  918]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.52      0.64      4673\n",
      "           1       0.29      0.69      0.41      1327\n",
      "\n",
      "    accuracy                           0.56      6000\n",
      "   macro avg       0.57      0.60      0.53      6000\n",
      "weighted avg       0.73      0.56      0.59      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7769\n",
      "- F1 score: 0.0630\n",
      "- Roc Auc Score: 0.5109\n",
      "Confusion Matrix: \n",
      " [[18465   226]\n",
      " [ 5129   180]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87     18691\n",
      "           1       0.44      0.03      0.06      5309\n",
      "\n",
      "    accuracy                           0.78     24000\n",
      "   macro avg       0.61      0.51      0.47     24000\n",
      "weighted avg       0.71      0.78      0.69     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7773\n",
      "- F1 score: 0.0525\n",
      "- Roc Auc Score: 0.5090\n",
      "Confusion Matrix: \n",
      " [[4627   46]\n",
      " [1290   37]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      4673\n",
      "           1       0.45      0.03      0.05      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.61      0.51      0.46      6000\n",
      "weighted avg       0.71      0.78      0.69      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9994\n",
      "- F1 score: 0.9987\n",
      "- Roc Auc Score: 0.9996\n",
      "Confusion Matrix: \n",
      " [[18677    14]\n",
      " [    0  5309]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7037\n",
      "- F1 score: 0.3341\n",
      "- Roc Auc Score: 0.5721\n",
      "Confusion Matrix: \n",
      " [[3776  897]\n",
      " [ 881  446]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      4673\n",
      "           1       0.33      0.34      0.33      1327\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.57      0.57      0.57      6000\n",
      "weighted avg       0.70      0.70      0.70      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9995\n",
      "- F1 score: 0.9989\n",
      "- Roc Auc Score: 0.9995\n",
      "Confusion Matrix: \n",
      " [[18681    10]\n",
      " [    2  5307]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7885\n",
      "- F1 score: 0.2883\n",
      "- Roc Auc Score: 0.5755\n",
      "Confusion Matrix: \n",
      " [[4474  199]\n",
      " [1070  257]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      4673\n",
      "           1       0.56      0.19      0.29      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.69      0.58      0.58      6000\n",
      "weighted avg       0.75      0.79      0.75      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8005\n",
      "- F1 score: 0.2961\n",
      "- Roc Auc Score: 0.5818\n",
      "Confusion Matrix: \n",
      " [[18205   486]\n",
      " [ 4302  1007]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88     18691\n",
      "           1       0.67      0.19      0.30      5309\n",
      "\n",
      "    accuracy                           0.80     24000\n",
      "   macro avg       0.74      0.58      0.59     24000\n",
      "weighted avg       0.78      0.80      0.75     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7947\n",
      "- F1 score: 0.2761\n",
      "- Roc Auc Score: 0.5736\n",
      "Confusion Matrix: \n",
      " [[4533  140]\n",
      " [1092  235]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      4673\n",
      "           1       0.63      0.18      0.28      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.72      0.57      0.58      6000\n",
      "weighted avg       0.77      0.79      0.75      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7886\n",
      "- F1 score: 0.2027\n",
      "- Roc Auc Score: 0.5498\n",
      "Confusion Matrix: \n",
      " [[18281   410]\n",
      " [ 4664   645]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88     18691\n",
      "           1       0.61      0.12      0.20      5309\n",
      "\n",
      "    accuracy                           0.79     24000\n",
      "   macro avg       0.70      0.55      0.54     24000\n",
      "weighted avg       0.76      0.79      0.73     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7850\n",
      "- F1 score: 0.1897\n",
      "- Roc Auc Score: 0.5447\n",
      "Confusion Matrix: \n",
      " [[4559  114]\n",
      " [1176  151]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88      4673\n",
      "           1       0.57      0.11      0.19      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.68      0.54      0.53      6000\n",
      "weighted avg       0.75      0.79      0.72      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Extra tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9994\n",
      "- F1 score: 0.9987\n",
      "- Roc Auc Score: 0.9996\n",
      "Confusion Matrix: \n",
      " [[18677    14]\n",
      " [    0  5309]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18691\n",
      "           1       1.00      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     24000\n",
      "   macro avg       1.00      1.00      1.00     24000\n",
      "weighted avg       1.00      1.00      1.00     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7933\n",
      "- F1 score: 0.2986\n",
      "- Roc Auc Score: 0.5805\n",
      "Confusion Matrix: \n",
      " [[4496  177]\n",
      " [1063  264]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      4673\n",
      "           1       0.60      0.20      0.30      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.70      0.58      0.59      6000\n",
      "weighted avg       0.76      0.79      0.75      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8759\n",
      "- F1 score: 0.6354\n",
      "- Roc Auc Score: 0.7373\n",
      "Confusion Matrix: \n",
      " [[18427   264]\n",
      " [ 2714  2595]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     18691\n",
      "           1       0.91      0.49      0.64      5309\n",
      "\n",
      "    accuracy                           0.88     24000\n",
      "   macro avg       0.89      0.74      0.78     24000\n",
      "weighted avg       0.88      0.88      0.86     24000\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7887\n",
      "- F1 score: 0.3361\n",
      "- Roc Auc Score: 0.5929\n",
      "Confusion Matrix: \n",
      " [[4411  262]\n",
      " [1006  321]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87      4673\n",
      "           1       0.55      0.24      0.34      1327\n",
      "\n",
      "    accuracy                           0.79      6000\n",
      "   macro avg       0.68      0.59      0.61      6000\n",
      "weighted avg       0.76      0.79      0.76      6000\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>F2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>0.412220</td>\n",
       "      <td>0.407638</td>\n",
       "      <td>0.540955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.703667</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.334082</td>\n",
       "      <td>0.335288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.875917</td>\n",
       "      <td>0.788667</td>\n",
       "      <td>0.635406</td>\n",
       "      <td>0.336126</td>\n",
       "      <td>0.272449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extra tree</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.298643</td>\n",
       "      <td>0.229605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.288278</td>\n",
       "      <td>0.222935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>0.794667</td>\n",
       "      <td>0.296089</td>\n",
       "      <td>0.276146</td>\n",
       "      <td>0.206757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.189698</td>\n",
       "      <td>0.135475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.776875</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>0.052482</td>\n",
       "      <td>0.034316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Classifier</td>\n",
       "      <td>0.778792</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Train Accuracy  Test Accuracy  Train_F1   Test_F1  \\\n",
       "1  Logistic Regression        0.556667       0.555333  0.412220  0.407638   \n",
       "3        Decision Tree        0.999417       0.703667  0.998683  0.334082   \n",
       "8              XGBoost        0.875917       0.788667  0.635406  0.336126   \n",
       "7           Extra tree        0.999417       0.793333  0.998683  0.298643   \n",
       "4        Random Forest        0.999500       0.788500  0.998871  0.288278   \n",
       "5       Gradient Boost        0.800500       0.794667  0.296089  0.276146   \n",
       "6             Adaboost        0.788583       0.785000  0.202703  0.189698   \n",
       "2                  SVM        0.776875       0.777333  0.062992  0.052482   \n",
       "0  Baseline Classifier        0.778792       0.778833  0.000000  0.000000   \n",
       "\n",
       "   F2-Score  \n",
       "1  0.540955  \n",
       "3  0.335288  \n",
       "8  0.272449  \n",
       "7  0.229605  \n",
       "4  0.222935  \n",
       "5  0.206757  \n",
       "6  0.135475  \n",
       "2  0.034316  \n",
       "0  0.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report1 = evaluate_models(X_train=X_train_pca, y_train=y_train, x_test=x_test_pca, y_test=y_test, models=models)\n",
    "report1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534d5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
